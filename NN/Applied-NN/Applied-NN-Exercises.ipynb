{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqCbHP46InsX"
      },
      "source": [
        "# Applied Neural Networks - Exercises\n",
        "\n",
        "**NOTICE:**\n",
        "1. You are allowed to work in groups of up to three people but **have to document** your group's\\\n",
        " members in the top cell of your notebook.\n",
        "2. **Comment your code**, explain what you do (refer to the slides). It will help you understand the topics\\\n",
        " and help me understand your thinking progress. Quality of comments will be graded.\n",
        "3. **Discuss** and analyze your results, **write-down your learnings**. These exercises are no programming\\\n",
        " exercises it is about learning and getting a touch for these methods. Such questions might be asked in the\\\n",
        " final exams.\n",
        " 4. Feel free to **experiment** with these methods. Change parameters think about improvements, write down\\\n",
        " what you learned. This is not only about collecting points for the final grade, it is about understanding\\\n",
        "  the methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISoCEcN2InsY"
      },
      "source": [
        "### Exercise 1 - Data Normalization and Standardization\n",
        "\n",
        "\n",
        "**Summary:** In this exercise you will implement the min-max normalization and standardization and compare it to\\\n",
        "sklearn's implementation. It is important to remember, that we always normalize or standardize for all samples\\\n",
        " over a single feature dimension.\n",
        "\n",
        "\n",
        "**Provided Code:** In the cell below I have provided you with a sample code to initialize some dummy data.\\\n",
        "The parameter ```n_samples``` defines the number of samples we have in the training set (the number of $x_i$)\\\n",
        "while ```n_features``` defines the number of dimensions of each sample feature vector.\n",
        "\n",
        "\n",
        "**Your Tasks in this exercise:**\n",
        "1. Implement the MinMax Normalization and Standardization.\n",
        "2. Use the ```MinMaxScaler``` and ```StandardScaler``` from sklearn to verify your results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ty9-FKVOInsY"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "x,y = make_regression(n_samples=10, n_features=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqQAKtdZInsZ"
      },
      "source": [
        "### Exercise 2 - Softmax\n",
        "\n",
        "**Summary:** In this exercise you will implement the softmax activation using the naive and numerically\\\n",
        "more stable log-sum variation.\n",
        "\n",
        "\n",
        "**Provided Code:** In the cell below there is some sample code that generates sample inputs.\n",
        "\n",
        "\n",
        "**Your Tasks in this exercise:**\n",
        "1. Implement the softmax function using the naive approach.\n",
        "2. Implement the softmax function using the log-sum trick.\n",
        "3. Compare your two implementations for numerical stability\\\n",
        "(experiment with different values of std) and verify\n",
        "your results using ```tf.nn.softmax```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7iDRYipInsZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "mu = 0\n",
        "std = 10\n",
        "xi = mu + std * np.random.randn(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZTItBCnInsZ"
      },
      "source": [
        "### Exercise 3 - Chess Endgames\n",
        "\n",
        "**Summary:** In this exercise your task is to predict the optimal depth-of-win for white in   \n",
        "chess-endgames. In particular, we will focus on **king-rook** vs. **king** endgames. The   \n",
        "possible outcomes are either a **draw** or a **number of moves** for white to win (0 to 16).\n",
        "\n",
        "\n",
        "**Provided Code:** The code below loads the original (*unprepared*) raw dataset.   \n",
        "You will have to prepare it accordingly to be used with neural nets.\n",
        "\n",
        "The structure of each row in the dataset is:\n",
        "1. White King column (a-h)\n",
        "2. White King row (1-8)\n",
        "3. White Rook column (a-h)\n",
        "4. White Rook row (1-8)\n",
        "5. Black King column (a-h)\n",
        "6. Black King row (1-8)\n",
        "7. Optimal depth-of-win for White in 0 to 16 moves or a draw\n",
        "\n",
        "\n",
        "**Your Tasks in this exercise:**\n",
        "1. Train a neural net to predict the depth-of-win (or draw) given a board position\n",
        "    * You will have to prepare your data accordingly to make it compatible   \n",
        "    with neural nets. Think about input and output encodings, normalization or standardization.\n",
        "    * Decide how you will model this problem as either regression or classification task.\n",
        "    * Build a fully connected neural net with appropriate configuration and loss and train it.\n",
        "    * Use appropriate cross-validation for training and validation (it is enough to use two datasets)\n",
        "2. Explain in writing:\n",
        "    * How and why did you prepared the data?\n",
        "    * How did you model the problem task?\n",
        "    * What is your neural network architecture/configuration/loss?\n",
        "    * Plot your loss while training.\n",
        "    * Interpret and explain your results.\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA4fVqA0Insa",
        "outputId": "9d275b2e-e945-490c-ddf4-b6a555d00ccb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-26 11:05:09--  https://github.com/shegenbart/Jupyter-Exercises/raw/main/data/chess_endgames.pickle\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/shegenbart/Jupyter-Exercises/main/data/chess_endgames.pickle [following]\n",
            "--2024-11-26 11:05:09--  https://raw.githubusercontent.com/shegenbart/Jupyter-Exercises/main/data/chess_endgames.pickle\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6284700 (6.0M) [application/octet-stream]\n",
            "Saving to: ‘../data/chess_endgames.pickle’\n",
            "\n",
            "chess_endgames.pick 100%[===================>]   5.99M  18.1MB/s    in 0.3s    \n",
            "\n",
            "2024-11-26 11:05:10 (18.1 MB/s) - ‘../data/chess_endgames.pickle’ saved [6284700/6284700]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/shegenbart/Jupyter-Exercises/raw/main/data/chess_endgames.pickle -P ../data\n",
        "import pickle\n",
        "with open('../data/chess_endgames.pickle', 'rb') as fd:\n",
        "    chess_endgames = pickle.load(fd)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chess_endgames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwgTIAD9KWlj",
        "outputId": "992b0f81-da1a-4afe-a7d0-f1eb4fb1f7bd"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['1', '1', '2', ..., '3', '2', '17'],\n",
              "       ['1', '1', '3', ..., '3', '2', '17'],\n",
              "       ['1', '1', '3', ..., '4', '1', '17'],\n",
              "       ...,\n",
              "       ['2', '1', '7', ..., '5', '7', '16'],\n",
              "       ['2', '1', '7', ..., '6', '5', '16'],\n",
              "       ['2', '1', '7', ..., '7', '5', '16']], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#prepare data\n",
        "\n",
        "#White King column (a-h)\n",
        "white_king = {\n",
        "    \"a\": 1,\n",
        "    \"b\": 2,\n",
        "    \"c\": 3,\n",
        "    \"d\": 4,\n",
        "    \"e\": 5,\n",
        "    \"f\": 6,\n",
        "    \"g\": 7,\n",
        "    \"h\": 8\n",
        "}\n",
        "\n",
        "#White Rook column (a-h)\n",
        "white_rook = {\n",
        "    \"a\": 1,\n",
        "    \"b\": 2,\n",
        "    \"c\": 3,\n",
        "    \"d\": 4,\n",
        "    \"e\": 5,\n",
        "    \"f\": 6,\n",
        "    \"g\": 7,\n",
        "    \"h\": 8\n",
        "}\n",
        "\n",
        "#Black King column (a-h)\n",
        "black_king = {\n",
        "    \"a\": 1,\n",
        "    \"b\": 2,\n",
        "    \"c\": 3,\n",
        "    \"d\": 4,\n",
        "    \"e\": 5,\n",
        "    \"f\": 6,\n",
        "    \"g\": 7,\n",
        "    \"h\": 8\n",
        "}\n",
        "\n",
        "#optimal depth\n",
        "opt_depth = {\n",
        "    \"zero\": 0,\n",
        "    \"one\": 1,\n",
        "    \"two\": 2,\n",
        "    \"three\": 3,\n",
        "    \"four\": 4,\n",
        "    \"five\": 5,\n",
        "    \"six\": 6,\n",
        "    \"seven\": 7,\n",
        "    \"eight\": 8,\n",
        "    \"nine\": 9,\n",
        "    \"ten\": 10,\n",
        "    \"eleven\": 11,\n",
        "    \"twelve\": 12,\n",
        "    \"thirteen\": 13,\n",
        "    \"fourteen\": 14,\n",
        "    \"fifteen\": 15,\n",
        "    \"sixteen\": 16,\n",
        "    \"draw\": 17\n",
        "}\n",
        "\n",
        "for i in range(len(chess_endgames)):\n",
        "  chess_endgames[i][0] = white_king.get(chess_endgames[i][0], chess_endgames[i][0])\n",
        "  chess_endgames[i][2] = white_rook.get(chess_endgames[i][2], chess_endgames[i][2])\n",
        "  chess_endgames[i][4] = black_king.get(chess_endgames[i][4], chess_endgames[i][4])\n",
        "  chess_endgames[i][6] = opt_depth.get(chess_endgames[i][6], chess_endgames[i][6])\n"
      ],
      "metadata": {
        "id": "gsjnV62GKoTE"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7cGjUB8fInsa"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential()\n"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Edit Metadata",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}